{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce16f38-6acc-43fb-815b-4bf066c5e0de",
   "metadata": {},
   "source": [
    "# Loading Data (Ingestion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d94fde-b6c9-4562-abb3-1e5d4ff42fff",
   "metadata": {},
   "source": [
    "This example is adapted from [Loading Data, Ingestion](https://docs.llamaindex.ai/en/stable/understanding/loading/loading/)\n",
    "\n",
    "Before your chosen LLM can act on your data, you first need to process the data and load it. This has parallels to data cleaning/feature engineering pipelines in the ML world, or ETL pipelines in the traditional data setting.\n",
    "\n",
    "This ingestion pipeline typically consists of three main stages:\n",
    "\n",
    "1. Load the data\n",
    "2. Transform the data\n",
    "3. Index and store the data\n",
    "\n",
    "We cover indexing/storage in [future](https://docs.llamaindex.ai/en/stable/understanding/indexing/indexing/) [sections](https://docs.llamaindex.ai/en/stable/understanding/storing/storing/). In this guide we'll mostly talk about loaders and transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8b617-7a83-46cb-adcb-cb7500350483",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Steps\n",
    "In this example we will\n",
    "1. Download some PDFs about Ray, a distributed compute framework\n",
    "2. Use the SimpleDirectoryReader to create a list of Documents\n",
    "3. Then use the VectorStoreIndex class to split, chunk and index the documents \n",
    "4. Finally run several queries over the documents using OpenAI's LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25297d2f-1d7a-4592-a893-0b7c5fdf5c01",
   "metadata": {},
   "source": [
    "## Loaders\n",
    "Before your chosen LLM can act on your data you need to load it. The way LlamaIndex does this is via data connectors, also called `Reader`. Data connectors ingest data from different data sources and format the data into Document objects. A `Document` is a collection of data (currently text, and in future, images and audio) and metadata about that data.\n",
    "\n",
    "### Loading using SimpleDirectoryReader\n",
    "The easiest reader to use is our SimpleDirectoryReader, which creates documents out of every file in a given directory. It is built in to LlamaIndex and can read a variety of formats including Markdown, PDFs, Word documents, PowerPoint decks, images, audio and video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c248a414-39cf-466c-a431-40ab918d7859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64880e1-5014-4b50-8c5f-a10b0e86fda2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-05 17:04:15--  https://www.usenix.org/system/files/osdi18-moritz.pdf\n",
      "Resolving www.usenix.org (www.usenix.org)... 23.185.0.4, 2620:12a:8001::4, 2620:12a:8000::4\n",
      "Connecting to www.usenix.org (www.usenix.org)|23.185.0.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5486963 (5.2M) [application/pdf]\n",
      "Saving to: ‘osdi18-moritz.pdf’\n",
      "\n",
      "osdi18-moritz.pdf   100%[===================>]   5.23M  7.12MB/s    in 0.7s    \n",
      "\n",
      "2024-08-05 17:04:16 (7.12 MB/s) - ‘osdi18-moritz.pdf’ saved [5486963/5486963]\n",
      "\n",
      "--2024-08-05 17:04:16--  https://assets.ctfassets.net/xjan103pcp94/7gZbuzVlgVWMfynUTQstOc/65cc8708700710dff229cf50bf09c5fb/9781098117160_7-18-22.pdf\n",
      "Resolving assets.ctfassets.net (assets.ctfassets.net)... 3.165.102.46, 3.165.102.21, 3.165.102.9, ...\n",
      "Connecting to assets.ctfassets.net (assets.ctfassets.net)|3.165.102.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4220592 (4.0M) [application/pdf]\n",
      "Saving to: ‘9781098117160_7-18-22.pdf’\n",
      "\n",
      "9781098117160_7-18- 100%[===================>]   4.02M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2024-08-05 17:04:16 (78.6 MB/s) - ‘9781098117160_7-18-22.pdf’ saved [4220592/4220592]\n",
      "\n",
      "--2024-08-05 17:04:16--  https://www.scs.stanford.edu/24sp-cs244b/notes/ray.pdf\n",
      "Resolving www.scs.stanford.edu (www.scs.stanford.edu)... 171.66.3.9, 2001:470:806d:1::9\n",
      "Connecting to www.scs.stanford.edu (www.scs.stanford.edu)|171.66.3.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80145 (78K) [application/pdf]\n",
      "Saving to: ‘ray.pdf’\n",
      "\n",
      "ray.pdf             100%[===================>]  78.27K   107KB/s    in 0.7s    \n",
      "\n",
      "2024-08-05 17:04:18 (107 KB/s) - ‘ray.pdf’ saved [80145/80145]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cd data && wget https://www.usenix.org/system/files/osdi18-moritz.pdf\n",
    "! cd data && wget https://assets.ctfassets.net/xjan103pcp94/7gZbuzVlgVWMfynUTQstOc/65cc8708700710dff229cf50bf09c5fb/9781098117160_7-18-22.pdf\n",
    "! cd data && wget https://www.scs.stanford.edu/24sp-cs244b/notes/ray.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8b496b-3736-4ff0-af8b-9bc97fd07c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f019d2cf-06e8-4750-8168-47a264ae052f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8465c9-0628-4bd2-9911-c12808ce6ccf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare credentials\n",
    "Load credentials from a .env file and the [python-dotenv package](https://pypi.org/project/python-dotenv/)\n",
    "\n",
    "```toml\n",
    "OPENAI_API_KEY=\"<KEY>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ff1171-31a1-4478-952d-de6ed048fc11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8f89c-726f-4dcf-a4ad-91a07df0c65f",
   "metadata": {},
   "source": [
    "### Index the documents\n",
    "We will use `VectorStoreIndex` to load the documents into the index\n",
    "\n",
    "When you use `from_documents`, your Documents are split into chunks and parsed into [Node objects](https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/), lightweight abstractions over text strings that keep track of metadata and relationships. By default, VectorStoreIndex stores everything in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a897c4-2a03-4dad-b295-3e6d2d55de78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a4075-cdca-4ed0-a0fe-470eb3612a08",
   "metadata": {},
   "source": [
    "### Run a query\n",
    "Query engine is a generic interface that allows you to ask question over your data.\n",
    "\n",
    "A query engine takes in a natural language query, and returns a rich response. It is most often (but not always) built on one or many [indexes](https://docs.llamaindex.ai/en/stable/module_guides/indexing/) via [retrievers](https://docs.llamaindex.ai/en/stable/module_guides/querying/retriever/). You can compose multiple query engines to achieve more advanced capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17af7dfe-538a-40af-bc62-26037bd11b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ray.remote\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What Python decorator is used to transform an ordinary Python function into a Ray function?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d93305-2960-4035-8661-c0c4577f2d12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray stores large objects which are several hundred megabytes in size in its distributed memory by using a lightweight chain replication layer on top of Redis.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How does Ray store large objects which are several hundred megabytes in size in its distributed memory?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d53f8028-3629-42f0-bff8-c43a11ab1e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a Ray cluster, you can start by importing Ray and initializing it using the `ray.init()` function. This will set up a Ray cluster on your local machine, utilizing all available cores as workers. If you wish to run Ray on a cluster other than your local machine, you would need to provide additional arguments to the `init` function. After initializing Ray, you can access the Ray dashboard at the specified URL to monitor the cluster.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How can I create a Ray cluster?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "458e8b46-f29d-4c02-9cee-7abf81996798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray supports a multi-user environment.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Does Ray support a multi-user or multi-tenant environment?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "595b2876-8adc-4af6-82e5-759d92ecfd19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create and handle secrets in a Ray cluster, you can use the `ray.put` and `ray.get` functions to securely store and retrieve sensitive information. Here is an example code snippet demonstrating how to handle secrets in a Ray cluster:\n",
      "\n",
      "```python\n",
      "import ray\n",
      "\n",
      "# Initialize Ray\n",
      "ray.init()\n",
      "\n",
      "# Define the secret information\n",
      "secret_data = \"my_secret_password\"\n",
      "\n",
      "# Store the secret data securely in the Ray cluster\n",
      "secret_id = ray.put(secret_data)\n",
      "\n",
      "# Retrieve the secret data from the Ray cluster\n",
      "retrieved_secret = ray.get(secret_id)\n",
      "\n",
      "# Print the retrieved secret data\n",
      "print(\"Retrieved secret data:\", retrieved_secret)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How do I create and handle secrets in a Ray cluster? Give me a code example of how do handle secrets in a Ray cluster\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 for Llama-Index",
   "language": "python",
   "name": "python311-llamaindex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
